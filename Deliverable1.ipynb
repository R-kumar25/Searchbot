{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gTTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJDX33zPk3KX",
        "outputId": "eaac4d91-a2d1-4f49-c339-e202e9c8f407"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gTTS\n",
            "  Downloading gTTS-2.5.4-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.11/dist-packages (from gTTS) (8.1.8)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->gTTS) (2025.1.31)\n",
            "Downloading gTTS-2.5.4-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: gTTS\n",
            "Successfully installed gTTS-2.5.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U4HcpoA_kvBc"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import json\n",
        "import os\n",
        "import urllib\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Any, Optional\n",
        "import requests\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from gtts import gTTS\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "\n",
        "# ============================ URL VALIDITY EVALUATION ============================\n",
        "\n",
        "def evaluate_url_authenticity(search_query: str, webpage_url: str) -> dict:\n",
        "    \"\"\"\n",
        "    Assesses the credibility of a given URL by analyzing domain reputation, content alignment, factual accuracy,\n",
        "    potential bias, and citation frequency.\n",
        "\n",
        "    Args:\n",
        "        search_query (str): The user's original search input.\n",
        "        webpage_url (str): The URL being assessed.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing scores for various credibility metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    # === Step 1: Retrieve Webpage Content ===\n",
        "    try:\n",
        "        response = requests.get(webpage_url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        parsed_html = BeautifulSoup(response.text, \"html.parser\")\n",
        "        extracted_text = \" \".join([p.text for p in parsed_html.find_all(\"p\")])\n",
        "    except Exception as error:\n",
        "        return {\"error\": f\"Unable to retrieve content: {str(error)}\"}\n",
        "\n",
        "    # === Step 2: Assess Domain Reputation (Placeholder for Moz API) ===\n",
        "    domain_reliability_score = 60  # Placeholder value on a scale of 0-100\n",
        "\n",
        "    # === Step 3: Measure Content Alignment (Semantic Similarity) ===\n",
        "    transformer_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
        "    relevance_score = util.pytorch_cos_sim(\n",
        "        transformer_model.encode(search_query),\n",
        "        transformer_model.encode(extracted_text)\n",
        "    ).item() * 100\n",
        "\n",
        "    # === Step 4: Validate Facts (Google Fact Check API) ===\n",
        "    factual_accuracy_score = verify_claims(extracted_text)\n",
        "\n",
        "    # === Step 5: Detect Potential Bias (Sentiment Analysis) ===\n",
        "    sentiment_analyzer = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
        "    sentiment_result = sentiment_analyzer(extracted_text[:512])[0]  # Process the first 512 characters only\n",
        "    bias_tendency_score = 100 if sentiment_result[\"label\"] == \"POSITIVE\" else 50 if sentiment_result[\"label\"] == \"NEUTRAL\" else 30\n",
        "\n",
        "    # === Step 6: Evaluate Citation Frequency (Google Scholar via SerpAPI) ===\n",
        "    reference_count = fetch_citation_count(webpage_url)\n",
        "    citation_reliability_score = min(reference_count * 10, 100)  # Normalize within 0-100 range\n",
        "\n",
        "    # === Step 7: Compute Overall Credibility Score ===\n",
        "    aggregate_credibility_score = (\n",
        "        (0.3 * domain_reliability_score) +\n",
        "        (0.3 * relevance_score) +\n",
        "        (0.2 * factual_accuracy_score) +\n",
        "        (0.1 * bias_tendency_score) +\n",
        "        (0.1 * citation_reliability_score)\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"Domain Reliability Score\": domain_reliability_score,\n",
        "        \"Content Alignment Score\": relevance_score,\n",
        "        \"Factual Accuracy Score\": factual_accuracy_score,\n",
        "        \"Bias Tendency Score\": bias_tendency_score,\n",
        "        \"Citation Reliability Score\": citation_reliability_score,\n",
        "        \"Overall Credibility Score\": aggregate_credibility_score\n",
        "    }\n",
        "\n",
        "# === Helper Function: Validate Claims via Google Fact Check API ===\n",
        "\n",
        "def verify_claims(content_text: str) -> int:\n",
        "    \"\"\"\n",
        "    Cross-references the extracted text with the Google Fact Check API.\n",
        "    Returns a credibility score between 0-100 based on factual verification.\n",
        "    \"\"\"\n",
        "    fact_check_api_url = f\"https://toolbox.google.com/factcheck/api/v1/claimsearch?query={content_text[:200]}\"\n",
        "    try:\n",
        "        response = requests.get(fact_check_api_url)\n",
        "        data = response.json()\n",
        "        if \"claims\" in data and data[\"claims\"]:\n",
        "            return 80  # Indicates content is found in fact-check databases\n",
        "        return 40  # No verification found\n",
        "    except:\n",
        "        return 50  # Default score indicating uncertainty\n",
        "\n",
        "# === Helper Function: Retrieve Citation Count via Google Scholar API ===\n",
        "\n",
        "def fetch_citation_count(webpage_url: str) -> int:\n",
        "    \"\"\"\n",
        "    Queries Google Scholar via SerpAPI to retrieve citation counts for a given webpage.\n",
        "    Returns the number of citations found.\n",
        "    \"\"\"\n",
        "    serpapi_key = \"YOUR_SERPAPI_KEY\"\n",
        "    search_params = {\"q\": webpage_url, \"engine\": \"google_scholar\", \"api_key\": serpapi_key}\n",
        "    try:\n",
        "        response = requests.get(\"https://serpapi.com/search\", params=search_params)\n",
        "        data = response.json()\n",
        "        return len(data.get(\"organic_results\", []))\n",
        "    except:\n",
        "        return 0  # Default assumption that no citations exist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"I have recently recovered from the flu, is it safe for me to visit my newborn niece?\"\n",
        "url_to_check = \"https://www.bhtp.com/blog/when-safe-to-travel-with-newborn/\"\n",
        "\n",
        "# Call the correct function name: evaluate_url_authenticity\n",
        "result = evaluate_url_authenticity(user_prompt, url_to_check)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uMr3Yrxll-t",
        "outputId": "3d841df5-911f-42e8-9264-e7b32437111f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Domain Reliability Score': 60, 'Content Alignment Score': 45.83556056022644, 'Factual Accuracy Score': 50, 'Bias Tendency Score': 30, 'Citation Reliability Score': 0, 'Overall Credibility Score': 44.75066816806793}\n"
          ]
        }
      ]
    }
  ]
}